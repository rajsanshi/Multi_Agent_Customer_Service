{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQgqrW/eLCIJ6w3Eb+EVUw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajsanshi/Multi_Agent_Customer_Service/blob/main/Mullti_Agent_Customer_Support.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **L3: Multi-agent Customer Support AutomationÂ¶**\n",
        "\n",
        "Agents perform:\n",
        "\n",
        "1.Role Playing\n",
        "2.Focus\n",
        "3.Tools\n",
        "4.Cooperation\n",
        "5.Guardrails\n",
        "6.Memory"
      ],
      "metadata": {
        "id": "5KMtUCldsPpc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "agGs55Ysqjo4"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install crewai"
      ],
      "metadata": {
        "id": "48hti4DEq_PE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent,Task,Crew"
      ],
      "metadata": {
        "id": "yP3LcftQrf_c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LLM**\n",
        "\n",
        "Running local model using ollama but using openai method by giving a fake api-key"
      ],
      "metadata": {
        "id": "1H56kpLleP21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-1111\"\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=\"ollama/llama3.2\",\n",
        "    base_url=\"http://localhost:11434/v1\"\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "g-N3odmSrx6k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Agents**"
      ],
      "metadata": {
        "id": "5Ub7q6cQd9Mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "support_agent = Agent(\n",
        "    role=\"Senior Support Representative\",\n",
        "    goal=\"Be the most friendly and helpful support representative in your team\",\n",
        "    backstory=(\n",
        "        \"You work at a software consulting firm and are now are now working on providing \"\n",
        "\t\t\"support to {customer}, a super important customer \"\n",
        "        \" for your company.\"\n",
        "\t\t\"You need to make sure that you provide the best support!\"\n",
        "\t\t\"Make sure to provide full complete answers, \"\n",
        "        \" and make no assumptions.\"\n",
        "    ),\n",
        "    llm=llm,\n",
        "    allow_delegation=False,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "0Uy8-gexrz0u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "support_quality_assurance_agent = Agent(\n",
        "\trole=\"Support Quality Assurance Specialist\",\n",
        "\tgoal=\"Get recognition for providing the \"\n",
        "    \"best support quality assurance in your team\",\n",
        "\tbackstory=(\n",
        "\t\t\"You work at software consulting firm and \"\n",
        "        \"are now working with your team \"\n",
        "\t\t\"on a request from {customer} ensuring that \"\n",
        "        \"the support representative is \"\n",
        "\t\t\"providing the best support possible.\\n\"\n",
        "\t\t\"You need to make sure that the support representative \"\n",
        "        \"is providing full\"\n",
        "\t\t\"complete answers, and make no assumptions.\"\n",
        "\t),\n",
        "  llm=llm,\n",
        "\tverbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "PcDu57bwuEG4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tools , Guardrails and Memory**"
      ],
      "metadata": {
        "id": "SIVTUPoZLUib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai_tools import SerperDevTool, \\\n",
        "                         ScrapeWebsiteTool, \\\n",
        "                         WebsiteSearchTool"
      ],
      "metadata": {
        "id": "SQi1LZTlLT6-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_scrape_tool = ScrapeWebsiteTool(\n",
        "    website_url=\"https://docs.langchain.com/\"\n",
        ")"
      ],
      "metadata": {
        "id": "f_A8Miq4LnQY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating Tasks**"
      ],
      "metadata": {
        "id": "0HxS0X2teDB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inquiry_resolution = Task(\n",
        "    description=(\n",
        "        \"{customer} just reached out with a super important ask:\\n\"\n",
        "\t    \"{inquiry}\\n\\n\"\n",
        "        \"{person} from {customer} is the one that reached out. \"\n",
        "\t\t\"Make sure to use everything you know \"\n",
        "        \"to provide the best support possible.\"\n",
        "\t\t\"You must strive to provide a complete \"\n",
        "        \"and accurate response to the customer's inquiry.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "\t    \"A detailed, informative response to the \"\n",
        "        \"customer's inquiry that addresses \"\n",
        "        \"all aspects of their question.\\n\"\n",
        "        \"The response should include references \"\n",
        "        \"to everything you used to find the answer, \"\n",
        "        \"including external data or solutions. \"\n",
        "        \"Ensure the answer is complete, \"\n",
        "\t\t\"leaving no questions unanswered, and maintain a helpful and friendly \"\n",
        "\t\t\"tone throughout.\"\n",
        "    ),\n",
        "\ttools=[docs_scrape_tool],\n",
        "    agent=support_agent,\n",
        ")"
      ],
      "metadata": {
        "id": "SDp9LN2ILvWz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quality_assurance_review = Task(\n",
        "    description=(\n",
        "        \"Review the response drafted by the Senior Support Representative for {customer}'s inquiry. \"\n",
        "        \"Ensure that the answer is comprehensive, accurate, and adheres to the \"\n",
        "\t\t\"high-quality standards expected for customer support.\\n\"\n",
        "        \"Verify that all parts of the customer's inquiry \"\n",
        "        \"have been addressed \"\n",
        "\t\t\"thoroughly, with a helpful and friendly tone.\\n\"\n",
        "        \"Check for references and sources used to \"\n",
        "        \" find the information, \"\n",
        "\t\t\"ensuring the response is well-supported and \"\n",
        "        \"leaves no questions unanswered.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A final, detailed, and informative response \"\n",
        "        \"ready to be sent to the customer.\\n\"\n",
        "        \"This response should fully address the \"\n",
        "        \"customer's inquiry, incorporating all \"\n",
        "\t\t\"relevant feedback and improvements.\\n\"\n",
        "\t\t\"Don't be too formal, we are a chill and cool company \"\n",
        "\t    \"but maintain a professional and friendly tone throughout.\"\n",
        "    ),\n",
        "    agent=support_quality_assurance_agent,\n",
        ")\n"
      ],
      "metadata": {
        "id": "Kfu1B7cRLzAD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating Crew**"
      ],
      "metadata": {
        "id": "ur3f7a4WeHv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crew = Crew(\n",
        "  agents=[support_agent, support_quality_assurance_agent],\n",
        "  tasks=[inquiry_resolution, quality_assurance_review],\n",
        "  verbose=True,\n",
        "  memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "CD5aMROZL4Ax"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "inputs = {\n",
        "    \"customer\": \"ACME Inc.\",\n",
        "    \"person\": \"Jane Doe\",\n",
        "    \"inquiry\": \"We are trying to integrate a memory component into our workflow with LangChain. How can we persist and retrieve conversation history?\"\n",
        "}\n",
        "\n",
        "result = crew.kickoff(inputs=inputs)\n",
        "\n",
        "Markdown(result)"
      ],
      "metadata": {
        "id": "M7Br3KKKMY8l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}